{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cartpole_QLearning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM9UrW7moE12uFu7SNaYEym"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xl7mDsoRA1-v","executionInfo":{"status":"ok","timestamp":1636587535399,"user_tz":-540,"elapsed":351,"user":{"displayName":"‍김성환[ 대학원석·박사통합과정재학 / 컴퓨터정보학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14151897512299933104"}},"outputId":"f669946a-2198-4bed-d915-982c3a8de87d"},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}]},{"cell_type":"code","metadata":{"id":"nm9OrhkQFZ4e"},"source":["!apt-get install -y xvfb x11-utils\n","!pip install gym[all]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A9qkRaUFAdKb","executionInfo":{"status":"ok","timestamp":1636587547915,"user_tz":-540,"elapsed":377,"user":{"displayName":"‍김성환[ 대학원석·박사통합과정재학 / 컴퓨터정보학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14151897512299933104"}}},"source":["%matplotlib inline\n","from pyvirtualdisplay import Display\n","import gym\n","import numpy as np\n","import random\n","import math\n","from time import sleep\n","import matplotlib.pyplot as plt"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"MoBdLA6GMq6i"},"source":["display = Display(visible=False, size=(400, 300)) \n","display.start()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbp45M4EA-3g","executionInfo":{"status":"ok","timestamp":1636587548997,"user_tz":-540,"elapsed":6,"user":{"displayName":"‍김성환[ 대학원석·박사통합과정재학 / 컴퓨터정보학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14151897512299933104"}}},"source":["## Initialize the \"Cart-Pole\" environment\n","env = gym.make('CartPole-v0')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"IgajS0GEBB_H","executionInfo":{"status":"ok","timestamp":1636587548997,"user_tz":-540,"elapsed":6,"user":{"displayName":"‍김성환[ 대학원석·박사통합과정재학 / 컴퓨터정보학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14151897512299933104"}}},"source":["## Defining the environment related constants\n","\n","# Number of discrete states (bucket) per state dimension\n","NUM_BUCKETS = (1, 1, 6, 3)  # (x, dx, theta, dtheta)\n","# Number of discrete actions\n","NUM_ACTIONS = env.action_space.n # (left, right)\n","# Bounds for each discrete state\n","STATE_BOUNDS = list(zip(env.observation_space.low, env.observation_space.high))\n","STATE_BOUNDS[1] = [-0.5, 0.5]\n","STATE_BOUNDS[3] = [-math.radians(50), math.radians(50)]\n","# Index of the action\n","ACTION_INDEX = len(NUM_BUCKETS)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"70h7M7YrBEKN"},"source":["## Creating a Q-Table for each state-action pair\n","q_table = np.zeros(NUM_BUCKETS + (NUM_ACTIONS,))\n","print(q_table)\n","print(q_table.shape)\n","\n","# Create lists to contain total rewards and steps per episode\n","rList = []\n","\n","## Learning related constants\n","MIN_EXPLORE_RATE = 0.01\n","MIN_LEARNING_RATE = 0.1\n","\n","## Defining the simulation related constants\n","NUM_EPISODES = 300\n","MAX_T = 250\n","STREAK_TO_END = 20\n","SOLVED_T = 199\n","DEBUG_MODE = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PCMOUZNIBv2b","executionInfo":{"status":"ok","timestamp":1636587549407,"user_tz":-540,"elapsed":6,"user":{"displayName":"‍김성환[ 대학원석·박사통합과정재학 / 컴퓨터정보학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14151897512299933104"}}},"source":["def get_explore_rate(t):\n","    if t >= 24:\n","        return max(MIN_EXPLORE_RATE, min(1, 1.0 - math.log10((t+1)/25)))\n","    else:\n","        return 1.0"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9I7oRd0CQKA","executionInfo":{"status":"ok","timestamp":1636587549408,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍김성환[ 대학원석·박사통합과정재학 / 컴퓨터정보학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14151897512299933104"}}},"source":["def get_learning_rate(t):\n","    if t >= 24:\n","         return max(MIN_LEARNING_RATE, min(0.5, 1.0 - math.log10((t+1)/25)))\n","    else:\n","         return 1.0"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIQ4zo1WCVr0","executionInfo":{"status":"ok","timestamp":1636587550029,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍김성환[ 대학원석·박사통합과정재학 / 컴퓨터정보학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14151897512299933104"}}},"source":["def state_to_bucket(state):\n","    bucket_indice = []\n","    for i in range(len(state)):\n","        if state[i] <= STATE_BOUNDS[i][0]:\n","            bucket_index = 0\n","        elif state[i] >= STATE_BOUNDS[i][1]:\n","            bucket_index = NUM_BUCKETS[i] - 1\n","        else:\n","            # Mapping the state bounds to the bucket array\n","            bound_width = STATE_BOUNDS[i][1] - STATE_BOUNDS[i][0]\n","            offset = (NUM_BUCKETS[i]-1)*STATE_BOUNDS[i][0]/bound_width\n","            scaling = (NUM_BUCKETS[i]-1)/bound_width\n","            bucket_index = int(round(scaling*state[i] - offset))\n","        bucket_indice.append(bucket_index)\n","    return tuple(bucket_indice)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ez-THW3wCY-L","executionInfo":{"status":"ok","timestamp":1636587550030,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍김성환[ 대학원석·박사통합과정재학 / 컴퓨터정보학과 ]","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14151897512299933104"}}},"source":["def simulate():\n","\n","    ## Instantiating the learning related parameters\n","    learning_rate = get_learning_rate(0)\n","    explore_rate = get_explore_rate(0)\n","    discount_factor = 0.99  # since the world is unchanging\n","\n","    num_streaks = 0\n","\n","    for episode in range(NUM_EPISODES):\n","        # Reset the environment\n","        obv = env.reset()\n","        # the initial state\n","        state = state_to_bucket(obv)\n","        rAll = 0\n","        \n","        for t in range(MAX_T):\n","            env.render()\n","\n","            # Select an action\n","            if random.random() < explore_rate:\n","                action = env.action_space.sample()\n","            # Select the action with the highest q\n","            else:\n","                action = np.argmax(q_table[state])\n","\n","            # Execute the action\n","            new_obv, reward, done, info = env.step(action)\n","            # Observe the result\n","            new_state = state_to_bucket(new_obv)\n","            \n","            # Update Q-Table with new knowledge using learning rate\n","            q_target = reward + discount_factor * np.amax(q_table[new_state])\n","            q_table[state + (action,)] += learning_rate * (q_target - q_table[state + (action,)]) # update\n","        \n","            # Setting up for the next iteration\n","            state = new_state\n","            rAll += reward\n","            \n","            # Print data\n","            if (DEBUG_MODE):\n","                print(\"\\nEpisode = %d\" % episode)\n","                print(\"t = %d\" % t)\n","                print(\"Action: %d\" % action)\n","                print(\"State: %s\" % str(state))\n","                print(\"Reward: %f\" % reward)\n","                print(\"Streaks: %d\" % num_streaks)\n","                print(\"\")\n","\n","            if done:\n","                print(\"Episode %d finished after %d time steps\" % (episode, t))\n","                # steps >= 199\n","                if (t >= SOLVED_T):\n","                    num_streaks += 1\n","                else:\n","                    num_streaks = 0\n","                    \n","                rList.append(rAll)\n","                break\n","\n","        # It's considered done when it's solved over 20 times consecutively\n","        if num_streaks > STREAK_TO_END:\n","            break\n","        \n","        # Update parameters\n","        explore_rate = get_explore_rate(episode)\n","        learning_rate = get_learning_rate(episode)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXCv_MIWE19J"},"source":["if __name__ == \"__main__\":\n","    simulate()\n","    env.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NydQU3DYE2Us"},"source":["plt.bar(range(len(rList)), rList, color=\"blue\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"exffu_1pN8pX"},"source":[""],"execution_count":null,"outputs":[]}]}
